{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2fe85bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x7fa72c0f53c0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from multiprocessing import Pool\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import nn\n",
    "\n",
    "py_file_location = \"...\"\n",
    "os.path.abspath(os.path.join(os.path.dirname(py_file_location), os.path.pardir))\n",
    "\n",
    "#from packages import *\n",
    "#from parameters import *\n",
    "\n",
    "from model_DL import *\n",
    "from functions import *\n",
    "from metrics import *\n",
    "from DNN_metrics import *\n",
    "from data_generator import *\n",
    "from loss_function import *\n",
    "from optimization import *\n",
    "\n",
    "\n",
    "\n",
    "tf.device('GPU:1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fe2459a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbr_train = int(1E6)\n",
    "\n",
    "Nbr_test = int(2E5) \n",
    "\n",
    "#outfile = 'Dataset/' # choose your path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "44809ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbr_test_bruteforce = 10000\n",
    "\n",
    "\n",
    "project_sub_path = \"Dataset_VF\"\n",
    "  \n",
    "# Parent Directory path\n",
    "parent_dir = \"\"\n",
    "### Train ###\n",
    "#dataset_train_Anne\n",
    "dataset_train = np.load(os.path.join(parent_dir,project_sub_path,'dataset_train_GF.npz'))\n",
    "\n",
    "h_11_tr = dataset_train['h_PP']\n",
    "h_12_tr = dataset_train['h_PS']\n",
    "h_1R_tr = dataset_train['h_PR']\n",
    "h_21_tr = dataset_train['h_SP']\n",
    "h_22_tr = dataset_train['h_SS']\n",
    "h_2R_tr = dataset_train['h_SR']\n",
    "h_R1_tr = dataset_train['h_RP']\n",
    "h_R2_tr = dataset_train['h_RS']\n",
    "\n",
    "\n",
    "#x_train_input = np.stack([h_11_tr, h_12_tr, h_1R_tr, h_21_tr, h_22_tr, h_2R_tr, h_R1_tr, h_R2_tr], axis=1)\n",
    "x_train = np.stack([h_R1_tr, h_11_tr, h_2R_tr, h_1R_tr, h_22_tr, h_R2_tr, h_21_tr, h_12_tr], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### VAL ###\n",
    "project_sub_path = \"Dataset_VF\"\n",
    "  \n",
    "# Parent Directory path\n",
    "parent_dir = \"\"\n",
    "#dataset_val_Anne\n",
    "\n",
    "dataset_test = np.load(os.path.join(parent_dir,project_sub_path,'dataset_val_GF.npz'))\n",
    "\n",
    "h_11_test = dataset_test['h_PP'][:Nbr_test_bruteforce]\n",
    "h_12_test = dataset_test['h_PS'][:Nbr_test_bruteforce]\n",
    "h_1R_test = dataset_test['h_PR'][:Nbr_test_bruteforce]\n",
    "h_21_test = dataset_test['h_SP'][:Nbr_test_bruteforce]\n",
    "h_22_test = dataset_test['h_SS'][:Nbr_test_bruteforce]\n",
    "h_2R_test = dataset_test['h_SR'][:Nbr_test_bruteforce]\n",
    "h_R1_test = dataset_test['h_RP'][:Nbr_test_bruteforce]\n",
    "h_R2_test = dataset_test['h_RS'][:Nbr_test_bruteforce]\n",
    "\n",
    "x_test = np.stack([h_R1_test, h_11_test, h_2R_test, h_1R_test, h_22_test, h_R2_test, h_21_test, h_12_test], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "613730fe",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "def loss_CF(Lambda=10**0.5, v_tau=0.25):\n",
    "    \n",
    "    def CF_loss(G, y_out):\n",
    "        \n",
    "        ''' compute loss for CF Relaying'''\n",
    "        \n",
    "        Tau = tf.constant(v_tau, dtype=tf.float32) # ==> Tau \n",
    "\n",
    "        W = tf.constant(Lambda, dtype=tf.float32)  # ==> lambda \n",
    "\n",
    "        G = tf.cast(G, dtype='float32')\n",
    "        \n",
    "        y_out = tf.cast(y_out, dtype='float32')\n",
    "\n",
    "        # index retrieval\n",
    "\n",
    "        Grp_indx, Gpp_indx, Gsr_indx, Gpr_indx, Gss_indx, Grs_indx, Gsp_indx, Gps_indx  = [0], [1], [2], [3], [4], [5], [6], [7]\n",
    "        \n",
    "        Pr_indx, Ps_indx  = [0], [1]\n",
    "\n",
    "        # tensors retrieval\n",
    "        Grp, Gpp, Gsr, Gpr, Gss, Grs, Gsp, Gps, Pr, Ps = tf.gather(G, Grp_indx, axis=1), tf.gather(G, Gpp_indx, axis=1), tf.gather(G, Gsr_indx, axis=1), tf.gather(G, Gpr_indx, axis=1), tf.gather(G, Gss_indx, axis=1), tf.gather(G, Grs_indx, axis=1), tf.gather(G, Gsp_indx, axis=1), tf.gather(G, Gps_indx, axis=1), tf.gather(y_out, Pr_indx, axis=1), tf.gather(y_out, Ps_indx, axis=1)\n",
    "\n",
    "        #  Primary power Creation\n",
    "\n",
    "        Pp = tf.multiply(tf.ones(tf.shape(Pr), dtype=tf.dtypes.float32),10.0)\n",
    "\n",
    "        # NS_Tilde :NS = gPS*PP +1\n",
    "\n",
    "        NS_Tilde = tf.add(tf.multiply(Gps,Pp),tf.constant(1, dtype=tf.float32))\n",
    "\n",
    "        #NR_Tilde : gPR*PP +1\n",
    "\n",
    "        NR_Tilde = tf.add(tf.multiply(Gpr,Pp),tf.constant(1, dtype=tf.float32))\n",
    "\n",
    "        # Rho_Z : sqrt(Gpr*Gps)*Pp/sqrt(NR_tilde*NS_tilde)\n",
    "\n",
    "        Rho_Z = tf.divide(tf.multiply(tf.sqrt(tf.multiply(Gpr,Gps)),Pp),tf.sqrt(tf.multiply(NR_Tilde,NS_Tilde)))\n",
    "\n",
    "        #K1 : Gsr*NS_Tilde+Gss*NR_Tilde-2*Rho_Z*sqrt(Gsr*Gss*NR_Tilde*NS_Tilde)\n",
    "\n",
    "        E1 = tf.add(tf.multiply(Gsr,NS_Tilde),tf.multiply(Gss,NR_Tilde))\n",
    "\n",
    "        E2 = tf.sqrt(tf.multiply(tf.multiply(tf.multiply(Gsr,Gss),NR_Tilde),NS_Tilde))\n",
    "\n",
    "        K1 = tf.math.subtract(E1,tf.multiply(tf.multiply(tf.constant(2, dtype=tf.float32),Rho_Z),E2))\n",
    "\n",
    "        #K2 : (1-Rho_Z**2)*NR_Tilde*NS_Tilde\n",
    "\n",
    "        K2 = tf.math.subtract(tf.constant(1, dtype=tf.float32),tf.pow(Rho_Z,tf.constant(1, dtype=tf.float32)))\n",
    "\n",
    "        # function A' ==> A'(Gpp) : ((Gpp*Pp)/((1+(Gpp*Pp))**(1-tau)-1))-1 ==> (Gpp*Pp)/(R1) \n",
    "\n",
    "        R1 = tf.add(tf.constant(1, dtype=tf.float32),tf.multiply(Gpp,Pp))\n",
    "        R1 = tf.pow(R1, tf.math.subtract(tf.constant(1, dtype=tf.float32),Tau))\n",
    "        R1 = tf.math.subtract(R1,tf.constant(1, dtype=tf.float32))\n",
    "\n",
    "        A_ = tf.subtract(tf.divide(tf.multiply(Gpp,Pp),R1),tf.constant(1, dtype=tf.float32))\n",
    "\n",
    "        # QoS : \n",
    "\n",
    "        # PR**2 and PS**2 because custom_sigmoid(x):  \n",
    "        # returns : Output of sigmoid function range between 0 and sqrt(10)\n",
    "\n",
    "        Qos = tf.add(tf.multiply(Gsp,tf.pow(Ps,2)),tf.multiply(Grp,tf.pow(Pr,2)))\n",
    "\n",
    "        Qos = tf.subtract(Qos, A_)\n",
    "\n",
    "        Qos = tf.multiply(W,tf.keras.activations.relu(Qos)) \n",
    "\n",
    "        # SNR : \n",
    "        num = tf.add(tf.multiply(tf.multiply(tf.multiply(K1,Grs),tf.pow(Ps,2)),tf.pow(Pr,2)),tf.add(tf.multiply(tf.multiply(Gss,tf.pow(Ps,2)),tf.multiply(K1,tf.pow(Ps,2))),tf.multiply(tf.multiply(Gss,tf.pow(Ps,2)),K2)))\n",
    "        \n",
    "        \n",
    "        d_num = tf.add(tf.multiply(tf.multiply(K2,Grs), tf.pow(Pr,2)),tf.add(tf.multiply(NS_Tilde,tf.multiply(K1,tf.pow(Ps,2))),tf.multiply(NS_Tilde,K2)))\n",
    "        \n",
    "        SNR_opt = tf.divide(num, d_num)\n",
    "\n",
    "        # R_S\n",
    "\n",
    "        Rs_opt =  tf.multiply(tf.constant(0.5, dtype=tf.float32),log2(tf.add(tf.constant(1,dtype=tf.float32),SNR_opt)))\n",
    "\n",
    "        #-n_SNR+n_Qos\n",
    "        res = tf.reduce_mean(-Rs_opt+Qos) \n",
    "\n",
    "\n",
    "        return res\n",
    "    return CF_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "23de645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_CF(X_train, f_loss, f_metrics, f_activation1, f_activation2, LR) :\n",
    "    \"\"\"\n",
    "\n",
    "      Structure of DL model for DF.\n",
    "\n",
    "      Parameters:\n",
    "         X_train: Channel gain array.\n",
    "         f_loss: Loss function.\n",
    "         f_metrics: List of metrics.\n",
    "         f_activation1: First activation function for the output.\n",
    "         f_activation2: Second activation function for the output.\n",
    "         LR : Learning rate.\n",
    "         \n",
    "      Returns:\n",
    "        DL model for CF.\n",
    "    \"\"\"\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = LR)\n",
    "    inputs = Input(shape=(X_train.shape[1]))\n",
    "    x = Dense(128, activation='relu')(inputs)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    output1 = Dense(1, activation=f_activation1)(x)\n",
    "    output2 = Dense(1, activation=f_activation2)(x)\n",
    "    merged = tf.keras.layers.Concatenate()([output1, output2])\n",
    "    model = Model(inputs=inputs, outputs=[merged])\n",
    "    model.compile(loss=f_loss, optimizer=opt, metrics=f_metrics)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a790e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary_rate_CF(hR2, h12, h1R, hR1, h22, h2R, h21, h11, PR, PS):\n",
    "\n",
    "    R_P = C((h11**2*P1)/(hR1**2*PR+h21**2*PS+1))\n",
    "\n",
    "    return R_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7af309c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Delta(G, y_out):\n",
    " \n",
    "    \"\"\"\n",
    "      Metrics used on DL model for Primary achievable rate degradation.\n",
    "      \n",
    "      Parameters:\n",
    "        G: Channel gain tensor.\n",
    "        y_out: Predicted parameter.\n",
    "      Returns:\n",
    "        Primary achievable rate degradation for each samples \n",
    "    \"\"\"\n",
    "    G = tf.cast(G, dtype='float32')\n",
    "    y_out = tf.cast(y_out, dtype='float32')\n",
    "    \n",
    "    # index retrieval\n",
    "\n",
    "\n",
    "    Grp_indx, Gpp_indx, Gsp_indx = [0], [1], [6]\n",
    "    Pr_indx, Ps_indx  = [0], [1]\n",
    "\n",
    "    # tensors retrieval\n",
    "    Grp, Gpp, Gsp, Pr, Ps = tf.gather(G, Grp_indx, axis=1), tf.gather(G, Gpp_indx, axis=1), tf.gather(G, Gsp_indx, axis=1),  tf.gather(y_out, Pr_indx, axis=1), tf.gather(y_out, Ps_indx, axis=1)\n",
    "    \n",
    "    \n",
    "    #  Pp Creation\n",
    "    Pp = tf.multiply(tf.ones(tf.shape(Pr), dtype=tf.dtypes.float32),10)\n",
    "    \n",
    "    # Rp : C((Gpp*Pp)/(Grp*Pr**2+Gsp*Ps**2+2*(np.sqrt(Gsp*Grp)*Alpha*Ps*Pr)+1) ==> C(H1/H2), where H1 = Gpp*Pp and H2 = R1+R2+1\n",
    "    H1 = tf.multiply(Gpp, Pp)\n",
    "\n",
    "    R1 =  tf.add(tf.multiply(Grp, tf.pow(Pr, 2)),tf.multiply(Gsp,tf.pow(Ps, 2)))\n",
    "\n",
    "    H2 = tf.add(R1, tf.constant(1,dtype=tf.float32))\n",
    "    \n",
    "    SNR_P = tf.divide(H1, H2)\n",
    "    \n",
    "    Rp =  tf.multiply(tf.constant(0.5, dtype=tf.float32),log2(tf.add(tf.constant(1,dtype=tf.float32),SNR_P)))\n",
    "\n",
    "    # Rp_ : C(Gpp*Pp)\n",
    "    SNR_P_ = tf.multiply(Gpp, Pp)\n",
    "    Rp_ = tf.multiply(tf.constant(0.5,dtype=tf.float32),log2(tf.add(tf.constant(1,dtype=tf.float32),SNR_P_)))\n",
    "    # 1 - ratio(Rp, Rp_)\n",
    "    RRP = tf.subtract(tf.constant(1,dtype=tf.float32), tf.divide(Rp, Rp_))\n",
    "    \n",
    "    return RRP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30238177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Opportunistic_Achievable_Rate(v_tau):\n",
    "    def opportunistic_rate(G, y_out):\n",
    "        \"\"\"\n",
    "        Metrics used on DL model for throughput calculation.\n",
    "        This function will get those parameters as input\n",
    "        G: Channel gain tensor.\n",
    "        y_out: Predicted parameter.\n",
    "\n",
    "        Parameters:\n",
    "        Lambda : Penalty for QoS\n",
    "        Tau : degradation factor for the primary network\n",
    "        Returns:\n",
    "        Throughput mean \n",
    "        \"\"\"\n",
    "\n",
    "        Tau = tf.constant(v_tau, dtype=tf.float32) # ==> Tau \n",
    "\n",
    "        G = tf.cast(G, dtype='float32')\n",
    "        y_out = tf.cast(y_out, dtype='float32')\n",
    "\n",
    "        # index retrieval\n",
    "    \n",
    "\n",
    "\n",
    "        Grp_indx, Gpp_indx, Gsr_indx, Gpr_indx, Gss_indx, Grs_indx, Gsp_indx, Gps_indx = [0], [1], [2], [3], [4], [5], [6], [7]\n",
    "        Pr_indx, Ps_indx  = [0], [1]\n",
    "\n",
    "        # tensors retrieval\n",
    "        Grp, Gpp, Gsr, Gpr, Gss, Grs, Gsp, Gps, Pr, Ps = tf.gather(G, Grp_indx, axis=1), tf.gather(G, Gpp_indx, axis=1), tf.gather(G, Gsr_indx, axis=1), tf.gather(G, Gpr_indx, axis=1), tf.gather(G, Gss_indx, axis=1), tf.gather(G, Grs_indx, axis=1), tf.gather(G, Gsp_indx, axis=1), tf.gather(G, Gps_indx, axis=1), tf.gather(y_out, Pr_indx, axis=1), tf.gather(y_out, Ps_indx, axis=1)\n",
    "        Pp = tf.multiply(tf.ones(tf.shape(Pr), dtype=tf.dtypes.float32),10)\n",
    "\n",
    "\n",
    "        NS_Tilde = tf.add(tf.multiply(Gps,Pp),tf.constant(1, dtype=tf.float32))\n",
    "\n",
    "        #NR_Tilde : gPR*PP +1\n",
    "\n",
    "        NR_Tilde = tf.add(tf.multiply(Gpr,Pp),tf.constant(1, dtype=tf.float32))\n",
    "\n",
    "        # Rho_Z : sqrt(Gpr*Gps)*Pp/sqrt(NR_tilde*NS_tilde)\n",
    "\n",
    "        Rho_Z = tf.divide(tf.multiply(tf.sqrt(tf.multiply(Gpr,Gps)),Pp),tf.sqrt(tf.multiply(NR_Tilde,NS_Tilde)))\n",
    "\n",
    "        #K1 : Gsr*NS_Tilde+Gss*NR_Tilde-2*Rho_Z*sqrt(Gsr*Gss*NR_Tilde*NS_Tilde)\n",
    "\n",
    "        E1 = tf.add(tf.multiply(Gsr,NS_Tilde),tf.multiply(Gss,NR_Tilde))\n",
    "\n",
    "        E2 = tf.sqrt(tf.multiply(tf.multiply(tf.multiply(Gsr,Gss),NR_Tilde),NS_Tilde))\n",
    "\n",
    "        K1 = tf.math.subtract(E1,tf.multiply(tf.multiply(tf.constant(2, dtype=tf.float32),Rho_Z),E2))\n",
    "\n",
    "        #K2 : (1-Rho_Z**2)*NR_Tilde*NS_Tilde\n",
    "\n",
    "        K2 = tf.math.subtract(tf.constant(1, dtype=tf.float32),tf.pow(Rho_Z,tf.constant(1, dtype=tf.float32)))\n",
    "\n",
    "        num = tf.add(tf.multiply(tf.multiply(tf.multiply(K1,Grs),tf.pow(Ps,2)),tf.pow(Pr,2)),tf.add(tf.multiply(tf.multiply(Gss,tf.pow(Ps,2)),tf.multiply(K1,tf.pow(Ps,2))),tf.multiply(tf.multiply(Gss,tf.pow(Ps,2)),K2)))\n",
    "                \n",
    "        d_num = tf.add(tf.multiply(tf.multiply(K2,Grs), tf.pow(Pr,2)),tf.add(tf.multiply(NS_Tilde,tf.multiply(K1,tf.pow(Ps,2))),tf.multiply(NS_Tilde,K2)))\n",
    "        \n",
    "        SNR_opt = tf.divide(num, d_num)\n",
    "\n",
    "        #C = 1/2*log2(1+SNR_opt)\n",
    "        # debit calculation\n",
    "        Rs = tf.multiply(tf.constant(0.5,dtype=tf.float32),log2(tf.add(tf.constant(1,dtype=tf.float32),SNR_opt)))\n",
    "        return Rs\n",
    "    return opportunistic_rate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a35440fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_126 (Dense)               (None, 128)          1152        input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_127 (Dense)               (None, 256)          33024       dense_126[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_128 (Dense)               (None, 256)          65792       dense_127[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_129 (Dense)               (None, 256)          65792       dense_128[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 1)            257         dense_129[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 1)            257         dense_129[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 2)            0           dense_130[0][0]                  \n",
      "                                                                 dense_131[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 166,274\n",
      "Trainable params: 166,274\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 4s 8ms/step - loss: 7.6586 - Delta: 0.2441 - opportunistic_rate: 0.1883 - val_loss: -0.0174 - val_Delta: 0.0434 - val_opportunistic_rate: 0.0239\n",
      "Epoch 2/100\n",
      "145/391 [==========>...................] - ETA: 1s - loss: -0.0240 - Delta: 0.0466 - opportunistic_rate: 0.0324"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_167761/627923313.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_CF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_CF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_sigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_sigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#lr_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEpochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Nbr_train = int(1E6)\n",
    "\n",
    " \n",
    "tau = 0.25\n",
    "\n",
    "VS = 0.2 # validation_split\n",
    "\n",
    "Epochs = 100 # Epochs number\n",
    "\n",
    "BS = 4096 # batch_size\n",
    "\n",
    "LD = 10**0.5\n",
    "\n",
    "LR = 10**-4\n",
    "\n",
    "metrics = [Delta, Opportunistic_Achievable_Rate(tau)] #, QoS_mean_DF, QoS_median_DF\n",
    "\n",
    "\n",
    "\n",
    "#Nbr_train = int(1E6)\n",
    "\n",
    "model = get_model_CF(x_train, loss_CF(LD,tau), metrics, custom_sigmoid, custom_sigmoid, LR) #lr_v\n",
    "history = model.fit(x_train, np.power(x_train,2), epochs=Epochs, batch_size=BS, validation_split = VS)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00cdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e89b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
